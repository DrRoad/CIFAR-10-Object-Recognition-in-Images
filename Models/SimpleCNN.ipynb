{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers, optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train_out.npy\")\n",
    "y_train = np.load(\"y_train_out.npy\")\n",
    "x_test = np.load(\"x_test_out.npy\")\n",
    "y_test = np.load(\"y_test_out.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one hot encoding of target labels\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseMapNum = 32\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(2*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(4*baseMapNum, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=\"Adam\",\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Using Data augmentation------------\n",
      "Epoch 1/20\n",
      "781/781 [==============================] - 2013s - loss: 1.9023 - acc: 0.4254 - val_loss: 1.2061 - val_acc: 0.5941\n",
      "Epoch 2/20\n",
      "781/781 [==============================] - 1943s - loss: 1.2858 - acc: 0.5889 - val_loss: 0.9902 - val_acc: 0.6807\n",
      "Epoch 3/20\n",
      "781/781 [==============================] - 1911s - loss: 1.0342 - acc: 0.6666 - val_loss: 0.9119 - val_acc: 0.7058\n",
      "Epoch 4/20\n",
      "781/781 [==============================] - 1861s - loss: 0.9072 - acc: 0.7050 - val_loss: 0.8021 - val_acc: 0.7461\n",
      "Epoch 5/20\n",
      "781/781 [==============================] - 1896s - loss: 0.8422 - acc: 0.7314 - val_loss: 0.7770 - val_acc: 0.7564\n",
      "Epoch 6/20\n",
      "781/781 [==============================] - 1864s - loss: 0.7955 - acc: 0.7499 - val_loss: 0.7156 - val_acc: 0.7840\n",
      "Epoch 7/20\n",
      "781/781 [==============================] - 1847s - loss: 0.7587 - acc: 0.7654 - val_loss: 0.6748 - val_acc: 0.7956\n",
      "Epoch 8/20\n",
      "781/781 [==============================] - 1865s - loss: 0.7256 - acc: 0.7798 - val_loss: 0.6505 - val_acc: 0.8050\n",
      "Epoch 9/20\n",
      "781/781 [==============================] - 1844s - loss: 0.7049 - acc: 0.7888 - val_loss: 0.6075 - val_acc: 0.8268\n",
      "Epoch 10/20\n",
      "781/781 [==============================] - 1861s - loss: 0.6870 - acc: 0.7972 - val_loss: 0.6027 - val_acc: 0.8301\n",
      "Epoch 11/20\n",
      "781/781 [==============================] - 1850s - loss: 0.6709 - acc: 0.8066 - val_loss: 0.6262 - val_acc: 0.8299\n",
      "Epoch 12/20\n",
      "781/781 [==============================] - 1861s - loss: 0.6594 - acc: 0.8142 - val_loss: 0.6168 - val_acc: 0.8326\n",
      "Epoch 13/20\n",
      "781/781 [==============================] - 1848s - loss: 0.6461 - acc: 0.8180 - val_loss: 0.5952 - val_acc: 0.8398\n",
      "Epoch 14/20\n",
      "781/781 [==============================] - 1847s - loss: 0.6374 - acc: 0.8236 - val_loss: 0.5906 - val_acc: 0.8408\n",
      "Epoch 15/20\n",
      "781/781 [==============================] - 1863s - loss: 0.6325 - acc: 0.8250 - val_loss: 0.5852 - val_acc: 0.8462\n",
      "Epoch 16/20\n",
      "781/781 [==============================] - 1844s - loss: 0.6307 - acc: 0.8292 - val_loss: 0.5806 - val_acc: 0.8482\n",
      "Epoch 17/20\n",
      "781/781 [==============================] - 1865s - loss: 0.6202 - acc: 0.8323 - val_loss: 0.5915 - val_acc: 0.8438\n",
      "Epoch 18/20\n",
      "781/781 [==============================] - 1867s - loss: 0.6145 - acc: 0.8368 - val_loss: 0.5765 - val_acc: 0.8504\n",
      "Epoch 19/20\n",
      "781/781 [==============================] - 1878s - loss: 0.6106 - acc: 0.8387 - val_loss: 0.5702 - val_acc: 0.8535\n",
      "Epoch 20/20\n",
      "781/781 [==============================] - 1917s - loss: 0.6022 - acc: 0.8402 - val_loss: 0.5624 - val_acc: 0.8595\n"
     ]
    }
   ],
   "source": [
    "if data_augmentation :\n",
    "    print(\"-------------Using Data augmentation------------\")\n",
    "     # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "    datagen.fit(x_train)\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=20,verbose=1,validation_data=(x_test,y_test))\n",
    "    \n",
    "else :\n",
    "    print(\"-----Not Using Data augmentation---------------\")\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size*4,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"simple_cnn_adam_20.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"simple_cnn_adam_20.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Using Data augmentation------------\n",
      "Epoch 1/20\n",
      "781/781 [==============================] - 1926s - loss: 0.5973 - acc: 0.8439 - val_loss: 0.5652 - val_acc: 0.8545\n",
      "Epoch 2/20\n",
      "781/781 [==============================] - 1947s - loss: 0.5953 - acc: 0.8455 - val_loss: 0.5526 - val_acc: 0.8639\n",
      "Epoch 3/20\n",
      "781/781 [==============================] - 1935s - loss: 0.5936 - acc: 0.8458 - val_loss: 0.5566 - val_acc: 0.8638\n",
      "Epoch 4/20\n",
      "781/781 [==============================] - 1953s - loss: 0.5848 - acc: 0.8496 - val_loss: 0.5774 - val_acc: 0.8564\n",
      "Epoch 5/20\n",
      "781/781 [==============================] - 1944s - loss: 0.5875 - acc: 0.8497 - val_loss: 0.5537 - val_acc: 0.8649\n",
      "Epoch 6/20\n",
      "781/781 [==============================] - 1964s - loss: 0.5821 - acc: 0.8515 - val_loss: 0.5619 - val_acc: 0.8600\n",
      "Epoch 7/20\n",
      "781/781 [==============================] - 1941s - loss: 0.5817 - acc: 0.8543 - val_loss: 0.5502 - val_acc: 0.8645\n",
      "Epoch 8/20\n",
      "781/781 [==============================] - 1948s - loss: 0.5773 - acc: 0.8554 - val_loss: 0.5627 - val_acc: 0.8657\n",
      "Epoch 9/20\n",
      "781/781 [==============================] - 1962s - loss: 0.5747 - acc: 0.8550 - val_loss: 0.5347 - val_acc: 0.8716\n",
      "Epoch 10/20\n",
      "781/781 [==============================] - 1937s - loss: 0.5712 - acc: 0.8569 - val_loss: 0.5395 - val_acc: 0.8689\n",
      "Epoch 11/20\n",
      "781/781 [==============================] - 1510s - loss: 0.5719 - acc: 0.8604 - val_loss: 0.5488 - val_acc: 0.8686\n",
      "Epoch 12/20\n",
      "781/781 [==============================] - 944s - loss: 0.5732 - acc: 0.8582 - val_loss: 0.5664 - val_acc: 0.8651\n",
      "Epoch 13/20\n",
      "781/781 [==============================] - 983s - loss: 0.5677 - acc: 0.8600 - val_loss: 0.5329 - val_acc: 0.8731\n",
      "Epoch 14/20\n",
      "781/781 [==============================] - 985s - loss: 0.5668 - acc: 0.8597 - val_loss: 0.5260 - val_acc: 0.8770\n",
      "Epoch 15/20\n",
      "781/781 [==============================] - 992s - loss: 0.5639 - acc: 0.8610 - val_loss: 0.5426 - val_acc: 0.8728\n",
      "Epoch 16/20\n",
      "781/781 [==============================] - 980s - loss: 0.5568 - acc: 0.8661 - val_loss: 0.5437 - val_acc: 0.8728\n",
      "Epoch 17/20\n",
      "781/781 [==============================] - 993s - loss: 0.5667 - acc: 0.8617 - val_loss: 0.5167 - val_acc: 0.8808\n",
      "Epoch 18/20\n",
      "781/781 [==============================] - 995s - loss: 0.5557 - acc: 0.8661 - val_loss: 0.5340 - val_acc: 0.8751\n",
      "Epoch 19/20\n",
      "781/781 [==============================] - 985s - loss: 0.5579 - acc: 0.8640 - val_loss: 0.5286 - val_acc: 0.8782\n",
      "Epoch 20/20\n",
      "781/781 [==============================] - 968s - loss: 0.5503 - acc: 0.8669 - val_loss: 0.5264 - val_acc: 0.8784\n"
     ]
    }
   ],
   "source": [
    "if data_augmentation :\n",
    "    print(\"-------------Using Data augmentation------------\")\n",
    "     # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "    datagen.fit(x_train)\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=20,verbose=1,validation_data=(x_test,y_test))\n",
    "    \n",
    "else :\n",
    "    print(\"-----Not Using Data augmentation---------------\")\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size*4,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"cifar_simple_cnn_adam_40.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"cifar10_90.62.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 62s    \n",
      "\n",
      "Test result: 90.620 loss: 0.379\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
