{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D,GlobalAveragePooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers, optimizers\n",
    "import numpy as np\n",
    "from keras.layers import Add\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger,EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"x_train_out.npy\")\n",
    "y_train = np.load(\"y_train_out.npy\")\n",
    "x_test = np.load(\"x_test_out.npy\")\n",
    "y_test = np.load(\"y_test_out.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one hot encoding of target labels\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Initial Convolutional layer which is common to all ResNet models.\n",
    "\"\"\"\"\n",
    "#Input : Input tensor\n",
    "#filter : No of Convolutional filters\n",
    "#stride : stride length \n",
    "#kernel_size : Convolutional filter size\n",
    "\n",
    "#NOTE : kernel size and stride length are 7 and 2 in resnet paper\n",
    "\n",
    "# Kernel size of 3 and stride length of 2 and 1 are tried for CIFAR-10 dataset because of low resolution of the images\n",
    "\n",
    "def initial_conv(Input, filters, stride = 1,kernel_size = 7):\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size=(kernel_size,kernel_size), strides = (stride,stride), padding = \"same\")(Input)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Residual Block with projection shortcut to match the dimensions using 1*1 convolutions.\n",
    "\n",
    "Note : This is basic residual Block, here all the convolutions are of same size and the depth is kept constant\n",
    "\n",
    "\"\"\"\"\n",
    "\n",
    "# Input : Input tensor\n",
    "# filters : No of Filters\n",
    "# Stride : stride length \n",
    "# Note : Stride 2 is used to downsample the image in CONV2,CONV3 and CONV4 blocks\n",
    "# Dropout : Adds Dropout layer if dropout is greater than 0\n",
    "\n",
    "def expand_conv_basic_block(Input, filters, stride=1, dropout = 0.0):\n",
    "    Init = Input\n",
    "    \n",
    "    #First conv which is used to downsample the image\n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (stride,stride),padding = \"same\")(Input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Optional Dropout layer\n",
    "    if(dropout > 0.0):\n",
    "        x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (1,1),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    #Projection shortcut to make skip connection(Paper terminology)\n",
    "    skip_conv = Conv2D(filters, kernel_size = (1,1),strides = (stride,stride),padding = \"same\")(Input)\n",
    "    skip = BatchNormalization()(skip_conv)\n",
    "    \n",
    "    #Skip connection\n",
    "    x = Add()([x,skip])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Residual networks with basic Identity shortcuts\n",
    "\n",
    "\"\"\"\n",
    "# Input : Input tensor\n",
    "# filters : No of Filters\n",
    "# Stride : stride length \n",
    "# Dropout : Adds Dropout layer if dropout is greater than 0\n",
    "\n",
    "def normal_conv_basic_block(Input, filters, stride = 1, dropout = 0.0):\n",
    "    \n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (stride,stride),padding = \"same\")(Input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Optional Dropout layer\n",
    "    if(dropout > 0.0):\n",
    "        x = Dropout(dropout)(x)\n",
    "    \n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (stride,stride),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    #Identity skip connection\n",
    "    x = Add()([x,Input])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Residual Block with projection shortcut to match the dimensions using 1*1 convolutions.\n",
    "\n",
    "Note : This is bottleneck residual block. Here first 1*1 convolution is used to reduce depth, followed by 3*3 \n",
    "        and last 1*1 is used to restore the depth\n",
    "\n",
    "\"\"\"\"\n",
    "\n",
    "# Input : Input tensor\n",
    "# filters : No of Filters\n",
    "# Stride : stride length \n",
    "# Note : Stride 2 is used to downsample the image in CONV2,CONV3 and CONV4 blocks\n",
    "# Dropout : Adds Dropout layer if dropout is greater than 0\n",
    "\n",
    "def expand_conv_bottleneck_block(Input,filters,stride=1,dropout = 0.0):\n",
    "    \n",
    "    #Contracting 1*1 conv\n",
    "    x = Conv2D(filters,kernel_size=(1,1),strides = (stride,stride),padding = \"same\")(Input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #if(dropout > 0.0):\n",
    "     #   x = Dropout(dropout)(x)\n",
    "    \n",
    "    #Depth preserving 3*3 conv\n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (1,1),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #if(Dropout > 0.0):\n",
    "     #   x = Dropout(dropout)(x)\n",
    "    \n",
    "    #Expanding 1*1 Conv\n",
    "    x = Conv2D(filters*4,kernel_size=(1,1),strides = (1,1),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    #Projection shortcut\n",
    "    skip_conv = Conv2D(filters*4,kernel_size = (1,1), strides = (stride, stride),padding = \"same\")(Input)\n",
    "    skip = BatchNormalization()(skip_conv)\n",
    "    \n",
    "    #Skip connection\n",
    "    x = Add()([x,skip])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Residual networks with bottleneck Identity shortcuts\n",
    "\n",
    "\"\"\"\n",
    "# Input : Input tensor\n",
    "# filters : No of Filters\n",
    "# Stride : stride length \n",
    "# Dropout : Adds Dropout layer if dropout is greater than 0\n",
    "\n",
    "\n",
    "def normal_conv_bottleneck_block(Input, filters, stride = 1, dropout = 0.0):\n",
    "    #Contracting 1*1 conv\n",
    "    x = Conv2D(filters,kernel_size=(1,1),strides = (stride,stride),padding = \"same\")(Input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #if(dropout > 0.0):\n",
    "     #   x = Dropout(dropout)(x)\n",
    "        \n",
    "    #Depth preserving 3*3 Conv\n",
    "    x = Conv2D(filters,kernel_size=(3,3),strides = (stride,stride),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "   # if(Dropout > 0.0):\n",
    "    #    x = Dropout(dropout)(x)\n",
    "    \n",
    "    #Expanding 1*1 Conv\n",
    "    x = Conv2D(filters*4,kernel_size=(1,1),strides = (stride,stride),padding = \"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    #Identity skip connection\n",
    "    x = Add()([x,Input])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper function to Build ResNet using basic residual blocks.\n",
    "Used when the total no of layers are less than 50.\n",
    "\n",
    "\"\"\"\n",
    "#h = height of the image\n",
    "#w = width of the image\n",
    "#no_of_outputs = no of classification classes\n",
    "#r1 = No of times first conv block should be repeated\n",
    "#r2 = No of times second conv block should be repeated\n",
    "#r3 = No of times third conv block should be repeated\n",
    "#r4 = No of times fourth conv block should be repeated\n",
    "\n",
    "# first_conv_stride = stride which will be used for initial conv block\n",
    "# first_max_pool = boolean to decide to apply max pooling or not\n",
    "# first_conv_size = kernel size which will be used for initial conv block\n",
    "\n",
    "#NOTE : The above three parameters are used only for cifar 10 data set coz of it's low resolution. \n",
    "        #For ImageNet Dataset they can be left as default\n",
    "\n",
    "\n",
    "def build_basic_resnet(h, w, no_of_outputs, r1,r2,r3,r4, first_conv_stride = 2, first_max_pool = True,first_conv_kernel_size = 7):\n",
    "    \n",
    "    #Creating input tensor\n",
    "    inputs = Input(shape = (h,w,3), name = \"image_input\")\n",
    "    \n",
    "    # Inital Conv block\n",
    "    x = initial_conv(inputs,64,first_conv_stride,first_conv_kernel_size)\n",
    "    \n",
    "    #Optional Max pooling layer\n",
    "    if(first_max_pool):\n",
    "        x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    \n",
    "\n",
    "    #Expanding block1 with projection shortcut\n",
    "    x = expand_conv_basic_block(x,64,1)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv1\n",
    "    for i in range(r1-1):\n",
    "        x = normal_conv_basic_block(x,64)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    #Expanding block2 with projection shortcut\n",
    "    x = expand_conv_basic_block(x,128,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv2\n",
    "    for i in range(r2-1):\n",
    "        x = normal_conv_basic_block(x,128)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    #Expanding block3 with projection shortcut\n",
    "    x = expand_conv_basic_block(x,256,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv3\n",
    "    for i in range(r3-1):\n",
    "        x = normal_conv_basic_block(x,256)\n",
    "        x = Activation('relu')(x)\n",
    "          \n",
    "     #Expanding block4 with projection shortcut\n",
    "    x = expand_conv_basic_block(x,512,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv3\n",
    "    for i in range(r4-1):\n",
    "        x = normal_conv_basic_block(x,512)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    shape = K.int_shape(x)\n",
    "    \n",
    "    #Average pooling layer\n",
    "    x = AveragePooling2D(pool_size=(shape[1], shape[2]),\n",
    "                                 strides=(1, 1))(x)\n",
    "   # x = GlobalAveragePooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    #Classifier Block\n",
    "    x = Dense(no_of_outputs,activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = x)\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_basic_resnet(32,32,10,2,2,2,2,1,False,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "image_input (InputLayer)         (None, 32, 32, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)              (None, 32, 32, 64)    9472        image_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchNo (None, 32, 32, 64)    256         conv2d_158[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_127 (Activation)      (None, 32, 32, 64)    0           batch_normalization_158[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)              (None, 32, 32, 64)    36928       activation_127[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchNo (None, 32, 32, 64)    256         conv2d_159[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_128 (Activation)      (None, 32, 32, 64)    0           batch_normalization_159[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)              (None, 32, 32, 64)    36928       activation_128[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)              (None, 32, 32, 64)    4160        activation_127[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchNo (None, 32, 32, 64)    256         conv2d_160[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchNo (None, 32, 32, 64)    256         conv2d_161[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_60 (Add)                     (None, 32, 32, 64)    0           batch_normalization_160[0][0]    \n",
      "                                                                   batch_normalization_161[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_129 (Activation)      (None, 32, 32, 64)    0           add_60[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)              (None, 32, 32, 64)    36928       activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchNo (None, 32, 32, 64)    256         conv2d_162[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_130 (Activation)      (None, 32, 32, 64)    0           batch_normalization_162[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)              (None, 32, 32, 64)    36928       activation_130[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchNo (None, 32, 32, 64)    256         conv2d_163[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_61 (Add)                     (None, 32, 32, 64)    0           batch_normalization_163[0][0]    \n",
      "                                                                   activation_129[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_131 (Activation)      (None, 32, 32, 64)    0           add_61[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)              (None, 16, 16, 128)   73856       activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchNo (None, 16, 16, 128)   512         conv2d_164[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_132 (Activation)      (None, 16, 16, 128)   0           batch_normalization_164[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)              (None, 16, 16, 128)   147584      activation_132[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)              (None, 16, 16, 128)   8320        activation_131[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchNo (None, 16, 16, 128)   512         conv2d_165[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchNo (None, 16, 16, 128)   512         conv2d_166[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_62 (Add)                     (None, 16, 16, 128)   0           batch_normalization_165[0][0]    \n",
      "                                                                   batch_normalization_166[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_133 (Activation)      (None, 16, 16, 128)   0           add_62[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)              (None, 16, 16, 128)   147584      activation_133[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchNo (None, 16, 16, 128)   512         conv2d_167[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_134 (Activation)      (None, 16, 16, 128)   0           batch_normalization_167[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)              (None, 16, 16, 128)   147584      activation_134[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchNo (None, 16, 16, 128)   512         conv2d_168[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_63 (Add)                     (None, 16, 16, 128)   0           batch_normalization_168[0][0]    \n",
      "                                                                   activation_133[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_135 (Activation)      (None, 16, 16, 128)   0           add_63[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)              (None, 8, 8, 256)     295168      activation_135[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchNo (None, 8, 8, 256)     1024        conv2d_169[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_136 (Activation)      (None, 8, 8, 256)     0           batch_normalization_169[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)              (None, 8, 8, 256)     590080      activation_136[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)              (None, 8, 8, 256)     33024       activation_135[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchNo (None, 8, 8, 256)     1024        conv2d_170[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchNo (None, 8, 8, 256)     1024        conv2d_171[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_64 (Add)                     (None, 8, 8, 256)     0           batch_normalization_170[0][0]    \n",
      "                                                                   batch_normalization_171[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_137 (Activation)      (None, 8, 8, 256)     0           add_64[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)              (None, 8, 8, 256)     590080      activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchNo (None, 8, 8, 256)     1024        conv2d_172[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_138 (Activation)      (None, 8, 8, 256)     0           batch_normalization_172[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)              (None, 8, 8, 256)     590080      activation_138[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchNo (None, 8, 8, 256)     1024        conv2d_173[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_65 (Add)                     (None, 8, 8, 256)     0           batch_normalization_173[0][0]    \n",
      "                                                                   activation_137[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_139 (Activation)      (None, 8, 8, 256)     0           add_65[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)              (None, 4, 4, 512)     1180160     activation_139[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchNo (None, 4, 4, 512)     2048        conv2d_174[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_140 (Activation)      (None, 4, 4, 512)     0           batch_normalization_174[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)              (None, 4, 4, 512)     2359808     activation_140[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)              (None, 4, 4, 512)     131584      activation_139[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchNo (None, 4, 4, 512)     2048        conv2d_175[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchNo (None, 4, 4, 512)     2048        conv2d_176[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_66 (Add)                     (None, 4, 4, 512)     0           batch_normalization_175[0][0]    \n",
      "                                                                   batch_normalization_176[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_141 (Activation)      (None, 4, 4, 512)     0           add_66[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)              (None, 4, 4, 512)     2359808     activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchNo (None, 4, 4, 512)     2048        conv2d_177[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_142 (Activation)      (None, 4, 4, 512)     0           batch_normalization_177[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)              (None, 4, 4, 512)     2359808     activation_142[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchNo (None, 4, 4, 512)     2048        conv2d_178[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_67 (Add)                     (None, 4, 4, 512)     0           batch_normalization_178[0][0]    \n",
      "                                                                   activation_141[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_143 (Activation)      (None, 4, 4, 512)     0           add_67[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePool (None, 1, 1, 512)     0           activation_143[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 512)           0           average_pooling2d_1[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            5130        flatten_7[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 11,200,458\n",
      "Trainable params: 11,190,730\n",
      "Non-trainable params: 9,728\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model,\"Resnet.png\",show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Helper function to Build ResNet using bottleneck residual blocks.\n",
    "Used when the total no of layers are more than 50.\n",
    "\n",
    "\"\"\"\n",
    "#h = height of the image\n",
    "#w = width of the image\n",
    "#no_of_outputs = no of classification classes\n",
    "#r1 = No of times first conv block should be repeated\n",
    "#r2 = No of times second conv block should be repeated\n",
    "#r3 = No of times third conv block should be repeated\n",
    "#r4 = No of times fourth conv block should be repeated\n",
    "\n",
    "# first_conv_stride = stride which will be used for initial conv block\n",
    "# first_max_pool = boolean to decide to apply max pooling or not\n",
    "# first_conv_size = kernel size which will be used for initial conv block\n",
    "\n",
    "#NOTE : The above three parameters are used only for cifar 10 data set coz of it's low resolution. \n",
    "        #For ImageNet Dataset they can be left as default\n",
    "\n",
    "\n",
    "def build_bottleneck_resnet(h, w, no_of_outputs, r1,r2,r3,r4, first_conv_stride = 2, first_max_pool = True,first_conv_kernel_size = 7):\n",
    "    \n",
    "    #Creating input tensor\n",
    "    inputs = Input(shape = (h,w,3), name = \"image_input\")\n",
    "    \n",
    "    # Inital Conv block\n",
    "    x = initial_conv(inputs,64,first_conv_stride,first_conv_kernel_size)\n",
    "    \n",
    "    #Optional Max pooling layer\n",
    "    if(first_max_pool):\n",
    "        x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "        \n",
    "    #Expanding block1 with projection shortcut\n",
    "    x = expand_conv_bottleneck_block(x,64,1)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv1\n",
    "    for i in range(r1-1):\n",
    "        x = normal_conv_bottleneck_block(x,64)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    #Expanding block2 with projection shortcut\n",
    "    x = expand_conv_bottleneck_block(x,128,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv2\n",
    "    for i in range(r2-1):\n",
    "        x = normal_conv_bottleneck_block(x,128)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    #Expanding block3 with projection shortcut\n",
    "    x = expand_conv_bottleneck_block(x,256,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv3\n",
    "    for i in range(r3-1):\n",
    "        x = normal_conv_bottleneck_block(x,256)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    #Expanding block4 with projection shortcut\n",
    "    x = expand_conv_bottleneck_block(x,512,2)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    #Repeating block of Conv4\n",
    "    for i in range(r4-1):\n",
    "        x = normal_conv_bottleneck_block(x,512)\n",
    "        x = Activation('relu')(x)\n",
    "    \n",
    "    shape = K.int_shape(x)\n",
    "    \n",
    "    #Average pooling layer\n",
    "    x = AveragePooling2D(pool_size=(shape[1], shape[2]),\n",
    "                                 strides=(1, 1))(x)\n",
    "   # x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    #Classifier Block\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(no_of_outputs,activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = x)\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_bottleneck_resnet(32,32,10,3,4,6,3,1,False,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model,\"Resnet_bottleneck.png\",show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "image_input (InputLayer)         (None, 32, 32, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)              (None, 32, 32, 64)    9472        image_input[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchNo (None, 32, 32, 64)    256         conv2d_208[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_169 (Activation)      (None, 32, 32, 64)    0           batch_normalization_208[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)              (None, 32, 32, 64)    4160        activation_169[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchNo (None, 32, 32, 64)    256         conv2d_209[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_170 (Activation)      (None, 32, 32, 64)    0           batch_normalization_209[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)              (None, 32, 32, 64)    36928       activation_170[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchNo (None, 32, 32, 64)    256         conv2d_210[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_171 (Activation)      (None, 32, 32, 64)    0           batch_normalization_210[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)              (None, 32, 32, 64)    0           activation_171[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)              (None, 32, 32, 256)   16640       dropout_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)              (None, 32, 32, 256)   16640       activation_169[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchNo (None, 32, 32, 256)   1024        conv2d_211[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchNo (None, 32, 32, 256)   1024        conv2d_212[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_76 (Add)                     (None, 32, 32, 256)   0           batch_normalization_211[0][0]    \n",
      "                                                                   batch_normalization_212[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_172 (Activation)      (None, 32, 32, 256)   0           add_76[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)              (None, 32, 32, 64)    16448       activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchNo (None, 32, 32, 64)    256         conv2d_213[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_173 (Activation)      (None, 32, 32, 64)    0           batch_normalization_213[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)              (None, 32, 32, 64)    36928       activation_173[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchNo (None, 32, 32, 64)    256         conv2d_214[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_174 (Activation)      (None, 32, 32, 64)    0           batch_normalization_214[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 32, 32, 64)    0           activation_174[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)              (None, 32, 32, 256)   16640       dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchNo (None, 32, 32, 256)   1024        conv2d_215[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_77 (Add)                     (None, 32, 32, 256)   0           batch_normalization_215[0][0]    \n",
      "                                                                   activation_172[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_175 (Activation)      (None, 32, 32, 256)   0           add_77[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)              (None, 32, 32, 64)    16448       activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchNo (None, 32, 32, 64)    256         conv2d_216[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_176 (Activation)      (None, 32, 32, 64)    0           batch_normalization_216[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)              (None, 32, 32, 64)    36928       activation_176[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchNo (None, 32, 32, 64)    256         conv2d_217[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_177 (Activation)      (None, 32, 32, 64)    0           batch_normalization_217[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 32, 32, 64)    0           activation_177[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)              (None, 32, 32, 256)   16640       dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchNo (None, 32, 32, 256)   1024        conv2d_218[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_78 (Add)                     (None, 32, 32, 256)   0           batch_normalization_218[0][0]    \n",
      "                                                                   activation_175[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_178 (Activation)      (None, 32, 32, 256)   0           add_78[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)              (None, 16, 16, 128)   32896       activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchNo (None, 16, 16, 128)   512         conv2d_219[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_179 (Activation)      (None, 16, 16, 128)   0           batch_normalization_219[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)              (None, 16, 16, 128)   147584      activation_179[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchNo (None, 16, 16, 128)   512         conv2d_220[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_180 (Activation)      (None, 16, 16, 128)   0           batch_normalization_220[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 16, 16, 128)   0           activation_180[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)              (None, 16, 16, 512)   66048       dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)              (None, 16, 16, 512)   131584      activation_178[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchNo (None, 16, 16, 512)   2048        conv2d_221[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchNo (None, 16, 16, 512)   2048        conv2d_222[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_79 (Add)                     (None, 16, 16, 512)   0           batch_normalization_221[0][0]    \n",
      "                                                                   batch_normalization_222[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_181 (Activation)      (None, 16, 16, 512)   0           add_79[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)              (None, 16, 16, 128)   65664       activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchNo (None, 16, 16, 128)   512         conv2d_223[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_182 (Activation)      (None, 16, 16, 128)   0           batch_normalization_223[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)              (None, 16, 16, 128)   147584      activation_182[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchNo (None, 16, 16, 128)   512         conv2d_224[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_183 (Activation)      (None, 16, 16, 128)   0           batch_normalization_224[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 16, 16, 128)   0           activation_183[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)              (None, 16, 16, 512)   66048       dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchNo (None, 16, 16, 512)   2048        conv2d_225[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_80 (Add)                     (None, 16, 16, 512)   0           batch_normalization_225[0][0]    \n",
      "                                                                   activation_181[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_184 (Activation)      (None, 16, 16, 512)   0           add_80[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)              (None, 16, 16, 128)   65664       activation_184[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchNo (None, 16, 16, 128)   512         conv2d_226[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_185 (Activation)      (None, 16, 16, 128)   0           batch_normalization_226[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)              (None, 16, 16, 128)   147584      activation_185[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchNo (None, 16, 16, 128)   512         conv2d_227[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_186 (Activation)      (None, 16, 16, 128)   0           batch_normalization_227[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 16, 16, 128)   0           activation_186[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)              (None, 16, 16, 512)   66048       dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchNo (None, 16, 16, 512)   2048        conv2d_228[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_81 (Add)                     (None, 16, 16, 512)   0           batch_normalization_228[0][0]    \n",
      "                                                                   activation_184[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_187 (Activation)      (None, 16, 16, 512)   0           add_81[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)              (None, 16, 16, 128)   65664       activation_187[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchNo (None, 16, 16, 128)   512         conv2d_229[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_188 (Activation)      (None, 16, 16, 128)   0           batch_normalization_229[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)              (None, 16, 16, 128)   147584      activation_188[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchNo (None, 16, 16, 128)   512         conv2d_230[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_189 (Activation)      (None, 16, 16, 128)   0           batch_normalization_230[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 16, 16, 128)   0           activation_189[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)              (None, 16, 16, 512)   66048       dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchNo (None, 16, 16, 512)   2048        conv2d_231[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_82 (Add)                     (None, 16, 16, 512)   0           batch_normalization_231[0][0]    \n",
      "                                                                   activation_187[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_190 (Activation)      (None, 16, 16, 512)   0           add_82[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)              (None, 8, 8, 256)     131328      activation_190[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchNo (None, 8, 8, 256)     1024        conv2d_232[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_191 (Activation)      (None, 8, 8, 256)     0           batch_normalization_232[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)              (None, 8, 8, 256)     590080      activation_191[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchNo (None, 8, 8, 256)     1024        conv2d_233[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_192 (Activation)      (None, 8, 8, 256)     0           batch_normalization_233[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 8, 8, 256)     0           activation_192[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)              (None, 8, 8, 1024)    263168      dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)              (None, 8, 8, 1024)    525312      activation_190[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchNo (None, 8, 8, 1024)    4096        conv2d_234[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchNo (None, 8, 8, 1024)    4096        conv2d_235[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_83 (Add)                     (None, 8, 8, 1024)    0           batch_normalization_234[0][0]    \n",
      "                                                                   batch_normalization_235[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_193 (Activation)      (None, 8, 8, 1024)    0           add_83[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)              (None, 8, 8, 256)     262400      activation_193[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchNo (None, 8, 8, 256)     1024        conv2d_236[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_194 (Activation)      (None, 8, 8, 256)     0           batch_normalization_236[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)              (None, 8, 8, 256)     590080      activation_194[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchNo (None, 8, 8, 256)     1024        conv2d_237[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_195 (Activation)      (None, 8, 8, 256)     0           batch_normalization_237[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 8, 8, 256)     0           activation_195[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)              (None, 8, 8, 1024)    263168      dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchNo (None, 8, 8, 1024)    4096        conv2d_238[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_84 (Add)                     (None, 8, 8, 1024)    0           batch_normalization_238[0][0]    \n",
      "                                                                   activation_193[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_196 (Activation)      (None, 8, 8, 1024)    0           add_84[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)              (None, 8, 8, 256)     262400      activation_196[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchNo (None, 8, 8, 256)     1024        conv2d_239[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_197 (Activation)      (None, 8, 8, 256)     0           batch_normalization_239[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)              (None, 8, 8, 256)     590080      activation_197[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchNo (None, 8, 8, 256)     1024        conv2d_240[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_198 (Activation)      (None, 8, 8, 256)     0           batch_normalization_240[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 8, 8, 256)     0           activation_198[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)              (None, 8, 8, 1024)    263168      dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchNo (None, 8, 8, 1024)    4096        conv2d_241[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_85 (Add)                     (None, 8, 8, 1024)    0           batch_normalization_241[0][0]    \n",
      "                                                                   activation_196[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_199 (Activation)      (None, 8, 8, 1024)    0           add_85[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)              (None, 8, 8, 256)     262400      activation_199[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchNo (None, 8, 8, 256)     1024        conv2d_242[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_200 (Activation)      (None, 8, 8, 256)     0           batch_normalization_242[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)              (None, 8, 8, 256)     590080      activation_200[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchNo (None, 8, 8, 256)     1024        conv2d_243[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_201 (Activation)      (None, 8, 8, 256)     0           batch_normalization_243[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)             (None, 8, 8, 256)     0           activation_201[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)              (None, 8, 8, 1024)    263168      dropout_19[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchNo (None, 8, 8, 1024)    4096        conv2d_244[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_86 (Add)                     (None, 8, 8, 1024)    0           batch_normalization_244[0][0]    \n",
      "                                                                   activation_199[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_202 (Activation)      (None, 8, 8, 1024)    0           add_86[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)              (None, 8, 8, 256)     262400      activation_202[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchNo (None, 8, 8, 256)     1024        conv2d_245[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_203 (Activation)      (None, 8, 8, 256)     0           batch_normalization_245[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)              (None, 8, 8, 256)     590080      activation_203[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchNo (None, 8, 8, 256)     1024        conv2d_246[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_204 (Activation)      (None, 8, 8, 256)     0           batch_normalization_246[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)             (None, 8, 8, 256)     0           activation_204[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)              (None, 8, 8, 1024)    263168      dropout_20[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchNo (None, 8, 8, 1024)    4096        conv2d_247[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_87 (Add)                     (None, 8, 8, 1024)    0           batch_normalization_247[0][0]    \n",
      "                                                                   activation_202[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_205 (Activation)      (None, 8, 8, 1024)    0           add_87[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)              (None, 8, 8, 256)     262400      activation_205[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchNo (None, 8, 8, 256)     1024        conv2d_248[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_206 (Activation)      (None, 8, 8, 256)     0           batch_normalization_248[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)              (None, 8, 8, 256)     590080      activation_206[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchNo (None, 8, 8, 256)     1024        conv2d_249[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_207 (Activation)      (None, 8, 8, 256)     0           batch_normalization_249[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, 8, 8, 256)     0           activation_207[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)              (None, 8, 8, 1024)    263168      dropout_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchNo (None, 8, 8, 1024)    4096        conv2d_250[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_88 (Add)                     (None, 8, 8, 1024)    0           batch_normalization_250[0][0]    \n",
      "                                                                   activation_205[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_208 (Activation)      (None, 8, 8, 1024)    0           add_88[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)              (None, 4, 4, 512)     524800      activation_208[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchNo (None, 4, 4, 512)     2048        conv2d_251[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_209 (Activation)      (None, 4, 4, 512)     0           batch_normalization_251[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)              (None, 4, 4, 512)     2359808     activation_209[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchNo (None, 4, 4, 512)     2048        conv2d_252[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_210 (Activation)      (None, 4, 4, 512)     0           batch_normalization_252[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)             (None, 4, 4, 512)     0           activation_210[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)              (None, 4, 4, 2048)    1050624     dropout_22[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)              (None, 4, 4, 2048)    2099200     activation_208[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchNo (None, 4, 4, 2048)    8192        conv2d_253[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchNo (None, 4, 4, 2048)    8192        conv2d_254[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_89 (Add)                     (None, 4, 4, 2048)    0           batch_normalization_253[0][0]    \n",
      "                                                                   batch_normalization_254[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_211 (Activation)      (None, 4, 4, 2048)    0           add_89[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)              (None, 4, 4, 512)     1049088     activation_211[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchNo (None, 4, 4, 512)     2048        conv2d_255[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_212 (Activation)      (None, 4, 4, 512)     0           batch_normalization_255[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)              (None, 4, 4, 512)     2359808     activation_212[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchNo (None, 4, 4, 512)     2048        conv2d_256[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_213 (Activation)      (None, 4, 4, 512)     0           batch_normalization_256[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)             (None, 4, 4, 512)     0           activation_213[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)              (None, 4, 4, 2048)    1050624     dropout_23[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchNo (None, 4, 4, 2048)    8192        conv2d_257[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_90 (Add)                     (None, 4, 4, 2048)    0           batch_normalization_257[0][0]    \n",
      "                                                                   activation_211[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_214 (Activation)      (None, 4, 4, 2048)    0           add_90[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)              (None, 4, 4, 512)     1049088     activation_214[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchNo (None, 4, 4, 512)     2048        conv2d_258[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_215 (Activation)      (None, 4, 4, 512)     0           batch_normalization_258[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)              (None, 4, 4, 512)     2359808     activation_215[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchNo (None, 4, 4, 512)     2048        conv2d_259[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_216 (Activation)      (None, 4, 4, 512)     0           batch_normalization_259[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)             (None, 4, 4, 512)     0           activation_216[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)              (None, 4, 4, 2048)    1050624     dropout_24[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchNo (None, 4, 4, 2048)    8192        conv2d_260[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "add_91 (Add)                     (None, 4, 4, 2048)    0           batch_normalization_260[0][0]    \n",
      "                                                                   activation_214[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_217 (Activation)      (None, 4, 4, 2048)    0           add_91[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePool (None, 1, 1, 2048)    0           activation_217[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)              (None, 2048)          0           average_pooling2d_3[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 10)            20490       flatten_9[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "        optimizer=\"Adam\",\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defining Callback functions which will be called by model during runtime when specified condition satisfies\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=2, min_lr=0.5e-6)\n",
    "csv_logger = CSVLogger('ResNet50_without_dropout_without_conv_without_pool.csv')\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=30)\n",
    "model_chekpoint = ModelCheckpoint(\"ResNet50_without_dropout_without_conv_without_pool.hdf5\",monitor = 'val_loss',verbose = 1,save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model Parameters\n",
    "batch_size = 64\n",
    "data_augmentation = True\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if data_augmentation :\n",
    "    print(\"-------------Using Data augmentation------------\")\n",
    "     # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "    \n",
    "    datagen.fit(x_train)\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=epochs,verbose=1,validation_data=(x_test,y_test),callbacks = [lr_reducer,early_stopper,csv_logger,model_chekpoint])\n",
    "    \n",
    "else :\n",
    "    print(\"-----Not Using Data augmentation---------------\")\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size*4,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
